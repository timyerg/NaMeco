{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c2204d-7e69-4f59-8d05-ea0d9573d246",
   "metadata": {},
   "source": [
    "# General variables and libraries\n",
    "Run this cell first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911daf9-7f39-4c18-8325-e7096b9ea842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import statsmodels.api as sm\n",
    "import colorcet as cc\n",
    "import matplotlib.patches as mpatches\n",
    "from patsy import ModelDesc\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['axes.linewidth'] = .5\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.facecolor'] = 'w'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "#VARIABLES\n",
    "OUT = 'Results/Standards'\n",
    "META = pd.read_csv('metadata.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "!mkdir -p Results Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0b466-fed9-4bb5-ad4d-7bc8cc2360c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70963ac7-2e97-413b-ae10-452e76f89398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install colorcet\n",
    "!qiime dev refresh-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf76556-fb50-4062-9a31-82419565b9c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concatenate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0810d4-d49b-4c3f-badc-9a9b38f162ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $BIG/../Cat_Lib2\n",
    "\n",
    "for bar in os.listdir(BIG):\n",
    "    inp = f\"{BIG}/{bar}/*.fastq.gz\"\n",
    "    out = f\"{BIG}/../Cat_Lib2/{bar}.fastq.gz\"\n",
    "    \n",
    "    !cat $inp > $out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf33be-94af-4e46-b489-4487807249c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename\n",
    "\n",
    "for index in META.index:\n",
    "    old = f\"{BIG}/../Cat_Lib2/{META.loc[index, 'BarcodeID']}.fastq.gz\"\n",
    "    new = f\"{BIG}/../Cat_Lib2/{index}.fastq.gz\"\n",
    "\n",
    "    !mv $old $new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22840975-985f-4d4d-bd35-6503ed995ebc",
   "metadata": {},
   "source": [
    "# 16S rRNAs from Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c353fb-e10c-480f-a39b-a5f173b93436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Results/16S_Standard\n",
    "\n",
    "ncbi = pd.read_csv(f'{OUT}/Final_output/NCBI-taxonomy.tsv', sep='\\t', index_col=0)\n",
    "gtdb = pd.read_csv(f'{OUT}/Final_output/GTDB-taxonomy.tsv', sep='\\t', index_col=0)\n",
    "STD = pd.read_csv('Data/standard.tsv', sep='\\t', index_col=0).T\n",
    "STD.sort_values(inplace=True, axis=1, by='D6306', ascending=True)\n",
    "genera = [c.split(' ')[0].replace('Lactobacillus', 'Limosilactobacillus') for c in STD.columns]\n",
    "\n",
    "df = gtdb[['Species', 'Perc. id.']].copy()\n",
    "df.columns = ['GTDB-Species', 'GTDB-Perc. id.']\n",
    "df[['NCBI-Species', 'NCBI-Perc. id.']] = ncbi[['Species', 'Perc. id.']]\n",
    "df = df.loc[df.index.str.contains('_16S_')]\n",
    "df.index = df.index.str.replace('_', ' ')\n",
    "df['Standard'] = df.index.str.split(' 16S').str[0]\n",
    "df['16S copy'] = df.index.str.split('16S ').str[-1].astype(int)\n",
    "df.sort_values([\"Standard\", '16S copy'], ascending=[True, True], inplace=True)\n",
    "df = df[['Standard', '16S copy', 'GTDB-Species', 'GTDB-Perc. id.', 'NCBI-Species', 'NCBI-Perc. id.']]\n",
    "\n",
    "df.to_csv('Results/16S_Standard/16S_Standard_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c3efcc-31b2-4101-a42b-61ff6da2bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for taxonomy annotation with Blast and NCBI\n",
    "def taxonomy_thresholds(bclust, thresholds):\n",
    "    for ind in bclust.index:\n",
    "        taxon = bclust.loc[ind, 'Taxon']\n",
    "        last = ''\n",
    "        for rank, perc in thresholds.items():\n",
    "            prefix = f\"{rank[0].lower()}__\"\n",
    "            pat = taxon.split(prefix)[-1].split(';')[0]\n",
    "            if bclust.loc[ind, 'pind'] >= perc:\n",
    "                last = pat\n",
    "            if bclust.loc[ind, 'pind'] < perc:\n",
    "                taxon = taxon.replace(prefix+pat, f\"{prefix}{last} unclassified\")\n",
    "                bclust.loc[ind, 'Taxon'] = taxon\n",
    "    return(bclust)\n",
    "\n",
    "def top_hit(bclust, taxa):\n",
    "    taxa_counts = bclust[\"Taxon\"].value_counts()\n",
    "    bclust[\"Taxa_counts\"] = bclust[\"Taxon\"].map(taxa_counts)\n",
    "    bclust.sort_values([\"Taxa_counts\", 'bitscore', 'pind'], ascending=[False, False, False], inplace=True)\n",
    "    taxon, pind = bclust.Taxon.iloc[0], bclust.pind.iloc[0]\n",
    "    if len(bclust.loc[bclust.Taxa_counts==bclust.Taxa_counts.max()])/len(bclust) < 1:\n",
    "        taxon = taxon.rsplit(';',1)[0] +\";\"+ taxon.rsplit(';',1)[-1].split(' ')[0] + ' unclassified'\n",
    "    return taxon, pind\n",
    "\n",
    "\n",
    "thresholds = {'Domain': 65, 'Phylum': 75, 'Class': 78.5,\n",
    "              'Order': 82, 'Family': 86.5, 'Genus': 94.5, 'Species': 98}\n",
    "taxa = pd.DataFrame(columns=['Taxon', 'Perc. id.'])\n",
    "gap = 1\n",
    "\n",
    "#select tophit taxonomy\n",
    "blast = pd.read_csv(f\"Results/16SrRNA_Standard/GTDB-blastn.tsv\", sep='\\t', header=None, \n",
    "        names=['Cluster', 'SeqID', 'eval', 'length', 'pind', 'nind', 'bitscore', 'score', 'gaps'])\n",
    "blast = blast.sort_values(['bitscore', 'eval'], ascending=[False, False])\n",
    "\n",
    "#get full taxonomies\n",
    "\n",
    "mapp = pd.read_csv(f'/home/ty/Big_data/NaMeco_Minion/Standards_out/Taxonomy_annotation/GTDB/map.tsv', sep='\\t')\n",
    "mapp.Taxonomy = mapp.Taxonomy.apply(lambda x: x.rsplit(';', 1)[0] +';'+ \n",
    "                ' '.join(x.rsplit(';', 1)[-1].replace('_', ' ').replace('  ', '__').split(' ')[:2]))\n",
    "mapping = dict(mapp[['SeqID', 'Taxonomy']].values)\n",
    "for cluster in blast.Cluster.unique():\n",
    "    bclust = blast.loc[blast.Cluster == cluster].copy()\n",
    "\n",
    "    #apply \"Gap\" filtering\n",
    "    bclust = bclust.loc[bclust.bitscore > bclust.bitscore.max() - gap]\n",
    "\n",
    "    #add taxonomies with proper percent identity thresholds\n",
    "    bclust['Taxon'] = bclust['SeqID'].map(mapping)\n",
    "    bclust = taxonomy_thresholds(bclust, thresholds)\n",
    "    #display(bclust)\n",
    "\n",
    "    #select top hit based on frequency\n",
    "    taxa.loc[cluster, ['Taxon', 'Perc. id.']] = top_hit(bclust, taxa)  \n",
    "taxa['Taxon'] = taxa.Taxon.str.split(';').str[-1]\n",
    "display(taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc04d3-24ec-4f5f-8f16-afc9eff30cc9",
   "metadata": {},
   "source": [
    "# Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7dedf-f211-444f-9273-b6be65593ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import statsmodels.api as sm\n",
    "#from statannot import add_stat_annotation\n",
    "import colorcet as cc\n",
    "import matplotlib.patches as mpatches\n",
    "from patsy import ModelDesc\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['axes.linewidth'] = .5\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.facecolor'] = 'w'\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "#VARIABLES\n",
    "OUT = 'Results/Hosts'\n",
    "META = pd.read_csv('metadata.tsv', sep='\\t', index_col=0)\n",
    "TAXA = f'{OUT}/GTDB-taxonomy.qza'\n",
    "TREE = f'{OUT}/rooted_tree.qza'\n",
    "TABLE = f'{OUT}/table.qza'\n",
    "COREM = f'{OUT}/Results/Core-metrics'\n",
    "REPSEQS = f'{OUT}/rep-seqs.qza'\n",
    "\n",
    "ALPHAS = {\n",
    "    'shannon': 'Shannon entropy',\n",
    "    'faith_pd': 'Faith\\'s PD',\n",
    "}\n",
    "\n",
    "MDICT = {\n",
    "    'Human': 'H',\n",
    "    'Pig': 'P',\n",
    "    'Chicken': 'v',\n",
    "}\n",
    "\n",
    "!mkdir -p {TABS} Results Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea14b5c-2178-4b9a-bfb0-16d7f10c6c21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import feature table\n",
    "!biom convert \\\n",
    "    -i {OUT}/cluster_counts.tsv \\\n",
    "    -o table.biom \\\n",
    "    --table-type=\"OTU table\" \\\n",
    "    --to-hdf5\n",
    "\n",
    "!qiime tools import \\\n",
    "    --input-path table.biom \\\n",
    "    --type 'FeatureTable[Frequency]' \\\n",
    "    --input-format BIOMV210Format \\\n",
    "    --output-path $TABLE\n",
    "\n",
    "!rm table.biom\n",
    "\n",
    "#import taxonomy\n",
    "!qiime tools import \\\n",
    "    --type 'FeatureData[Taxonomy]' \\\n",
    "    --input-path {OUT}/GTDB-taxonomy-q2.tsv \\\n",
    "    --output-path {TAXA}\n",
    "\n",
    "#import representative sequences\n",
    "!qiime tools import \\\n",
    "    --type 'FeatureData[Sequence]' \\\n",
    "    --input-path {OUT}/rep_seqs.fasta \\\n",
    "    --output-path {REPSEQS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9de4e-a91c-4c06-9760-7fa78ec63314",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering to remove unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde05bf2-8ec2-41bd-bf4f-aa2b742ee5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabv = TABLE.replace('qza', 'qzv')\n",
    "\n",
    "#by domain\n",
    "!qiime taxa filter-table \\\n",
    "    --i-table $TABLE \\\n",
    "    --i-taxonomy $TAXA \\\n",
    "    --p-include d__Bacteria \\\n",
    "    --o-filtered-table $TABLE\n",
    "\n",
    "#remove organelles\n",
    "!qiime taxa filter-table \\\n",
    "    --i-table $TABLE \\\n",
    "    --i-taxonomy $TAXA \\\n",
    "    --p-exclude mitochondria,chloroplast \\\n",
    "    --o-filtered-table $TABLE\n",
    "\n",
    "#remove features, not annotated to the phylum level \n",
    "!qiime taxa filter-table \\\n",
    "    --i-table $TABLE \\\n",
    "    --i-taxonomy $TAXA \\\n",
    "    --p-include p__ \\\n",
    "    --o-filtered-table $TABLE\n",
    "\n",
    "#samples by features depth\n",
    "!qiime feature-table filter-samples \\\n",
    "    --i-table $TABLE \\\n",
    "    --p-min-frequency 5000 \\\n",
    "    --o-filtered-table $TABLE\n",
    "\n",
    "#summarize\n",
    "!qiime feature-table summarize \\\n",
    "    --i-table $TABLE \\\n",
    "    --m-sample-metadata-file metadata.tsv \\\n",
    "    --o-visualization $tabv\n",
    "\n",
    "#repseqs by feature table\n",
    "!qiime feature-table filter-seqs \\\n",
    "    --i-data $REPSEQS \\\n",
    "    --i-table $TABLE \\\n",
    "    --o-filtered-data $REPSEQS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c67ca2-42d5-4de7-b2b6-cf2c3e28318b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plant a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771a033-5d66-49e0-8364-636ff83467ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!qiime phylogeny align-to-tree-mafft-fasttree \\\n",
    "    --i-sequences $REPSEQS \\\n",
    "    --p-n-threads 4 \\\n",
    "    --o-alignment Data/aligned.qza \\\n",
    "    --o-masked-alignment Data/masked.qza \\\n",
    "    --o-tree Data/unrooted.qza \\\n",
    "    --o-rooted-tree $TREE\n",
    "\n",
    "!rm Data/aligned.qza Data/masked.qza Data/unrooted.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c936e-6607-415c-b144-16c2406ce52b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Core-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77c13a-d354-4580-99d6-eff32c55dbab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!qiime diversity core-metrics-phylogenetic \\\n",
    "    --i-table $TABLE \\\n",
    "    --i-phylogeny $TREE \\\n",
    "    --p-sampling-depth 80000 \\\n",
    "    --m-metadata-file metadata.tsv \\\n",
    "    --p-n-jobs-or-threads 'auto' \\\n",
    "    --output-dir $COREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac64341-cf5e-4fcc-8e4a-f5d31e4cc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to unzip matrix\n",
    "def get_matrix(qza):\n",
    "    a = !unzip $qza\n",
    "    out = a[1].split('/')[0].replace('  inflating: ','')\n",
    "    inf = out + '/data/distance-matrix.tsv'\n",
    "    matrix = pd.read_csv(inf,index_col=0,sep='\\t')\n",
    "    !rm -rf $out\n",
    "    return matrix\n",
    "\n",
    "# Unzipping qza pcoa\n",
    "def parse_pcoa(qza): \n",
    "    a = !unzip $qza\n",
    "    digest = a[1].split('/')[0].replace('  inflating: ', '')\n",
    "    inf = digest + '/data/ordination.txt'\n",
    "    lines = open(inf, 'r').readlines()\n",
    "    Eigvals = [float(i) for i in lines[1].rstrip().split('\\t')]\n",
    "    Proportion = [float(i) for i in lines[4].rstrip().split('\\t')]\n",
    "    pca_skipr = len(open(inf,'r').read().split('Site')[0].splitlines()) + 1\n",
    "    pcoa = pd.read_csv(inf, index_col=0, skiprows=pca_skipr, skipfooter=4,\\\n",
    "                       header=None, sep='\\t', engine='python')\n",
    "    !rm -r $digest\n",
    "    return  pcoa, Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e20753-d490-4539-8664-cd311c35e6b1",
   "metadata": {},
   "source": [
    "## PCoA plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f322b72-0209-4696-8391-fd54de5fab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pcoa\n",
    "\n",
    "x, y = 1, 2 # axes to plot\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(2.2, 2), \n",
    "                         gridspec_kw={'wspace': .12, 'width_ratios': [2, .1]})\n",
    "\n",
    "ordin, Prop = parse_pcoa(f'{COREM}/bray_curtis_pcoa_results.qza')\n",
    "ordin[['Host']] = META[['Host']]\n",
    "#pca_meta = META.loc[META.index.isin(ordin.index)].copy()\n",
    "ax = axes[0]\n",
    "plot = sns.scatterplot(x=x, y=y, data=ordin, ax=ax, linewidth=0.25, legend=False,\n",
    "                      style='Host', markers=MDICT, s=40, c='black')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel(f'PC{y:d} {Prop[y-1]*100:.2f}%', fontsize=6, labelpad=-4)\n",
    "ax.set_xlabel(f'PC{x:d} {Prop[x-1]*100:.2f}%', fontsize=6, labelpad=-2)\n",
    "    \n",
    "# legend\n",
    "ax = axes[-1]\n",
    "ax.axis('off')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, 1)\n",
    "yax, xax = .96, -.3\n",
    "ystep, xstep = .1, 1\n",
    "fsize = 6\n",
    "\n",
    "#ax.text(xax-.5, yax -.012, 'phyRPCA', fontsize=fsize)\n",
    "\n",
    "#yax -= ystep*1.5\n",
    "ax.text(xax-.5, yax -.015, 'Host:', fontsize=fsize)\n",
    "for k,v in MDICT.items():\n",
    "    yax -= ystep\n",
    "    sns.scatterplot(x=[xax], y=[yax], ax=ax, s=40, clip_on=False, c='black', marker=v)\n",
    "    ax.text(xax + 1, yax -.018, k, fontsize=fsize)\n",
    "\n",
    "plt.savefig(f'Figures/PCoA_BC_hosts.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2fc88e-327d-4ec0-9a15-92a5e28ef97e",
   "metadata": {},
   "source": [
    "## Alpha Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79844f4e-6df3-41b3-8b2d-9b9be2a32dd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add alpha metrics to metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f90419-d1bc-47ca-b0b3-783912506812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_alpha(qza):  \n",
    "    a = !unzip $qza\n",
    "    out = a[1].split('/')[0].replace('  inflating: ', '')\n",
    "    inf = f'{out}/data/alpha-diversity.tsv'\n",
    "    df = pd.read_csv(inf, sep='\\t', index_col=0)\n",
    "    !rm -rf $out\n",
    "    return df \n",
    "\n",
    "for alpha in ALPHAS:\n",
    "    data = add_alpha(f'{COREM}/{alpha}_vector.qza')\n",
    "    META.loc[META.index.isin(data.index), alpha] = data.iloc[:, 0]\n",
    "display(META)\n",
    "META.to_csv('metadata.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c852b-26e1-4d13-96ea-375a6ae82e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 2\n",
    "alphas = ['shannon', 'faith_pd']\n",
    "\n",
    "\n",
    "#set figure\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(2.3, 1.8), sharex='col',\n",
    "            gridspec_kw={'wspace': .2, 'hspace': .1})\n",
    "#axs, i = [[r, c] for r in range(rows) for c in range(cols)], 0\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    data = META[(META[alpha].notna())].copy()\n",
    "    \n",
    "    ### Boxplots ###\n",
    "    ax = axes[i]\n",
    "    \n",
    "    sns.boxplot(x='Host', y=alpha, data=data, ax=ax, linewidth=0.4, fliersize=0.3, \n",
    "                order=MDICT, color='white', showfliers=True)\n",
    "    sns.swarmplot(x='Host', y=alpha, data=data, order=MDICT, ax=ax, size=2,\n",
    "                  c='black', alpha=0.9, legend=False)\n",
    "    ax.tick_params(axis='both', labelsize=5.5, length=1.5, pad=1, width=0.5, direction='inout')\n",
    "    ax.tick_params(axis='x', labelsize=6, )\n",
    "\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    if alpha == alphas[0]:\n",
    "        ax.set_ylabel('Alpha diversity', fontsize=7, )\n",
    "\n",
    "    ax.text(.5, 1.04, ALPHAS[alpha], ha='center', fontsize=7, transform=ax.transAxes)\n",
    "    \n",
    "    #line color/width\n",
    "    for patch in ax.patches:\n",
    "        patch.set_edgecolor('black')\n",
    "        patch.set_linewidth(.5)\n",
    "    plt.setp(ax.lines, color='k', lw=.5)\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "  \n",
    "fig.align_labels()\n",
    "#fig.suptitle(ALPHAS[alpha], fontsize=7, y=.97)\n",
    "plt.savefig(f'Figures/Alpha_Hosts.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed9d29d-66d5-4190-a363-dcd127000117",
   "metadata": {},
   "source": [
    "## Percent Identity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f2ff1-9452-4166-98cc-71882ae165c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.read_csv(f'{OUT}/cluster_counts.tsv', sep='\\t', index_col=0)\n",
    "taxons = pd.read_csv(f'{OUT}/GTDB-taxonomy.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "dfs = []\n",
    "for host in MDICT:\n",
    "    count = counts[[c for c in counts.columns if c.endswith(host[0].upper())]].copy()\n",
    "    count = count.loc[~(count==0).all(axis=1)]\n",
    "    count['Percent identity'] = taxons['Perc. id.']\n",
    "    count = count[['Percent identity']]\n",
    "    count['Host'] = host\n",
    "    dfs.append(count)\n",
    "    \n",
    "data = pd.concat(dfs)\n",
    "data.to_csv(f'{OUT}/Hosts_Pind.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e29253-1b1e-4471-baf0-08e052980112",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 1\n",
    "\n",
    "#set figure\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(1, 1.6))\n",
    "\n",
    "#data\n",
    "data = pd.read_csv(f'{OUT}/Hosts_Pind.csv')\n",
    "\n",
    "### Boxplots ###\n",
    "sns.boxplot(x='Host', y='Percent identity', data=data, ax=ax, linewidth=0.4, fliersize=0.3, \n",
    "            order=MDICT, color='white', showfliers=False, )\n",
    "sns.swarmplot(x='Host', y='Percent identity', data=data, order=MDICT, ax=ax, size=1, \n",
    "              alpha=0.6, legend=False, c='black', )\n",
    "ax.tick_params(axis='both', labelsize=4.5, length=1.5, pad=1, width=0.5, direction='inout')\n",
    "ax.tick_params(axis='x', labelsize=5, )\n",
    "ax.set_xlabel('') \n",
    "ax.set_ylabel('Percent identity', fontsize=5.5, labelpad=0)\n",
    "#ax.text(.5, 1.14, \"GTDB vs NCBI\", ha='center', fontsize=7, transform=ax.transAxes)\n",
    "\n",
    "#line color/width\n",
    "for patch in ax.patches:\n",
    "    patch.set_edgecolor('black')\n",
    "    patch.set_linewidth(.5)\n",
    "plt.setp(ax.lines, color='k', lw=.5)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "plt.savefig(f'Figures/Pind_hosts.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d6e1c-a344-4b97-bb57-12614a9ecf95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Taxabarplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922be47-c54c-489a-8c8b-4137f55ce957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install colorcet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f308bb5-1e17-4bf0-9713-98d74d7daa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p Results/Taxabarplots\n",
    "    \n",
    "!qiime taxa barplot \\\n",
    "    --i-table {TABLE} \\\n",
    "    --i-taxonomy {TAXA} \\\n",
    "    --m-metadata-file metadata.tsv \\\n",
    "    --o-visualization Results/Taxabarplots/GTDB-taxabarplot-hosts.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3a6f6-c8a1-45d4-a279-60357210d80c",
   "metadata": {},
   "source": [
    "### Import libraries and declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb291b4-ca2b-465f-b82c-e10b76af53f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colours = cc.glasbey_hv\n",
    "del colours[26] #remove white color\n",
    "\n",
    "\n",
    "def bar_unzip(qza, lev):    \n",
    "    a = !unzip $qza\n",
    "    digest = a[1].split('/')[0].replace('  inflating: ', '')\n",
    "    inf = digest + f'/data/level-{lev}.csv'\n",
    "    data = pd.read_csv(inf, sep=',', index_col=0)\n",
    "    !rm -rf $digest\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c229de3-75ef-4da9-89db-6f4506beeb30",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Taxabarplots DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff5414-2ee1-48c6-83bb-85de645e85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drep = {\n",
    "    '_': ' ',\n",
    "    ';': ' ',\n",
    "}\n",
    "\n",
    "top = 20\n",
    "rows, cols = 1, len(MDICT)\n",
    "\n",
    "#figure\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4.5, 2.5), gridspec_kw={'wspace': 5})\n",
    "#axs, i = [[r, c] for r in range(rows) for c in range(cols)], 0\n",
    "\n",
    "#data\n",
    "df = bar_unzip(f'Results/Taxabarplots/GTDB-taxabarplot-hosts.qzv', 7)\n",
    "df = df[[col for col in df.columns if 'p__' in col]]\n",
    "meta = META.loc[df.index].copy()\n",
    "#df = df.groupby(level=0, axis=1).sum() #sum duplicates\n",
    "df.loc['mean', :] = df.mean() #add a row with mean \n",
    "df.sort_values(inplace=True, axis=1, by='mean', ascending=True) #sort features by mean of abundances\n",
    "df.drop(inplace=True, index='mean')\n",
    "df = df.div(df.sum(axis=1), axis=0) * 100 #convert to % (rel ab)\n",
    "for k, v in drep.items():\n",
    "    df.columns = [c.replace(k, v) for c in df.columns]\n",
    "df.columns = [c.strip(' ').split('  ')[-1] for c in df.columns]\n",
    "df.to_csv(f'Results/Taxabarplots/GTDB-taxabarplot-hosts', sep='\\t')\n",
    "#display(df)\n",
    "\n",
    "#cmap\n",
    "cdict = dict(zip(df.columns.tolist()[::-1], colours))\n",
    "\n",
    "for i, group in enumerate(MDICT):\n",
    "    legend = []\n",
    "    md = meta.loc[(META.Host == group)]\n",
    "    data = df.loc[md.index].copy()\n",
    "    data.loc['mean', :] = data.mean() #add a row with mean\n",
    "    data.sort_values(inplace=True, axis=1, by='mean', ascending=True) #sort features by mean of abundances\n",
    "    data.drop(inplace=True, index='mean')\n",
    "    data = data[data.columns.tolist()[-top:]]\n",
    "    data = data.sort_values(data.columns[-1])\n",
    "\n",
    "    #ax, i = axes[axs[i][0]][axs[i][1]], i+1\n",
    "    ax = axes[i]\n",
    "    bottom = [100 - data.loc[j,:].sum() for j in data.index] #starting points for stacked barplot\n",
    "    ax.bar(x=data.index, height=bottom, color='lightgrey', width=.95, linewidth=0)\n",
    "\n",
    "    for col in data.columns: #iterate through all features\n",
    "        c = cdict[col] #define color\n",
    "        if col not in legend: \n",
    "            legend = [col] + legend #add color to legend\n",
    "        ax.bar(x=data.index, height=data[col], bottom=bottom, color=c, label=col, width=.95, linewidth=0)\n",
    "        bottom = [a + b for a, b in zip(bottom, data[col].tolist())] #update bottom \n",
    "\n",
    "    #aesthetics\n",
    "    ax.tick_params(axis='both', labelsize=4.5, pad=.5, length=.5, width=0.5) #adjust ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim(0, 100) #set limit for y axis\n",
    "    ax.set_xlim(-.5, len(data.index) - .5) #set limit for x axis\n",
    "    ax.set_ylabel('', fontsize=6.5, labelpad=0)\n",
    "    ax.text(.5, 1.02, group, ha='center', fontsize=5, transform=ax.transAxes)\n",
    "    if group == list(MDICT.keys())[0]:\n",
    "        ax.set_ylabel(f'Relative abundance (%)', fontsize=6, labelpad=0)\n",
    "    \n",
    "    #legend\n",
    "    labels = legend + ['others']                     \n",
    "    handles = [mpatches.Patch(color='lightgrey', label=l) if l == 'others' \\\n",
    "              else mpatches.Patch(color=cdict[l], label=l) for l in labels]\n",
    "\n",
    "    leg = ax.legend(handles, labels ,loc=2, bbox_to_anchor=(1, 1.03), fontsize=4.5, frameon=False,\n",
    "                    handletextpad=0.5, handlelength=0.5, bbox_transform=ax.transAxes)  \n",
    "\n",
    "plt.savefig(f'Figures/Taxabarplot_hosts.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d64b0f-bbe3-44a6-bee6-bae90454bfe0",
   "metadata": {},
   "source": [
    "# Other tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2238eea-bac9-458e-9b60-93a20c33883f",
   "metadata": {},
   "source": [
    "## NanoCLUST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09f4c2-ddba-4222-b01b-28e02a782e0e",
   "metadata": {},
   "source": [
    "### GTDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f001d-ada4-40fd-b660-89e12b4e7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextflow run main.nf \\\n",
    "    -resume \\\n",
    "    -profile docker \\\n",
    "    --reads \"Standards/*.fastq.gz\" \\\n",
    "    --db \"GTDB/ssu_all.fna\" \\\n",
    "    --polishing_reads 1000 \\\n",
    "    --min_cluster_size 500 \\\n",
    "    --outdir NanoCLUST_GTDB \\\n",
    "    --min_cluster_size 500\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf5ca4-d71f-4c16-bed9-1601d39c1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxonomy_thresholds(bclust, thresholds):\n",
    "    for ind in bclust.index:\n",
    "        taxon = bclust.loc[ind, 'Taxon']\n",
    "        last = ''\n",
    "        for rank, perc in thresholds.items():\n",
    "            prefix = f\"{rank[0].lower()}__\"\n",
    "            pat = taxon.split(prefix)[-1].split(';')[0]\n",
    "            if bclust.loc[ind, 'per_ident'] >= perc:\n",
    "                last = pat\n",
    "            if bclust.loc[ind, 'per_ident'] < perc:\n",
    "                taxon = taxon.replace(prefix+pat, f\"{prefix}{last} unclassified\")\n",
    "            bclust.loc[ind, 'Taxon_masked'] = taxon\n",
    "    return(bclust)\n",
    "\n",
    "thresholds = {'Domain': 61, 'Phylum': 69, 'Class': 75,\n",
    "              'Order': 83, 'Family': 90, 'Genus': 93, 'Species': 98}\n",
    "\n",
    "mapp = pd.read_csv(f'/home/ty/Big_data/NaMeco_Minion/Standards_out/Taxonomy_annotation/GTDB/map.tsv', sep='\\t')\n",
    "mapp.Taxonomy = mapp.Taxonomy.apply(lambda x: x.rsplit(';', 1)[0] +';'+ \n",
    "                ' '.join(x.rsplit(';', 1)[-1].replace('_', ' ').replace('  ', '__').split(' ')[:2]))\n",
    "mapping = dict(mapp[['SeqID', 'Taxonomy']].values)\n",
    "dfs = []\n",
    "for i in range(1,6):\n",
    "    df = pd.read_csv(f\"Results/NanoCLUST_GTDB/C{i}S.fastq.nanoclust_out.txt\", sep=';',)\n",
    "    df['Sample'] = f\"C{i}S\"\n",
    "    df = df[['Sample', 'reads_in_cluster', 'taxid', 'per_ident', 'id']]\n",
    "    dfs.append(df)\n",
    "\n",
    "NC = pd.concat(dfs, ignore_index=True)\n",
    "NC['Taxon'] = NC['taxid'].map(mapping)\n",
    "NC = taxonomy_thresholds(NC, thresholds)\n",
    "NC.to_csv(\"Results/NanoCLUST_GTDB/NanoCLUST_taxonomy.tsv\", sep='\\t')\n",
    "display(NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734eb172-9b49-4c6c-93f0-fd3dde131831",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"Results/Tools\"\n",
    "\n",
    "NC = pd.read_csv(\"Results/NanoCLUST_GTDB/NanoCLUST_taxonomy.tsv\", sep='\\t', index_col=0)\n",
    "\n",
    "NC = NC.pivot(index=['id', 'Taxon'], columns='Sample', values='reads_in_cluster')\n",
    "NC = NC.groupby(['Taxon']).sum()\n",
    "NC.index = NC.index.str.split('s__').str[-1]\n",
    "NC = NC.reindex(sorted(NC.columns), axis=1)\n",
    "NC.to_csv(\"Results/Tools/NanoCLUST_GTDB.tsv\", sep='\\t')\n",
    "NC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb2feb-2d9d-4555-93f1-88870f4cf8e7",
   "metadata": {},
   "source": [
    "### NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c779832-d515-46f9-ba22-98f62276c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextflow run main.nf \\\n",
    "    -resume \\\n",
    "    -profile docker \\\n",
    "    --reads \"Standards/*.fastq.gz\" \\\n",
    "    --db \"NCBI/16S_ribosomal_RNA\" \\\n",
    "    --tax \"NCBI/\" \\\n",
    "    --polishing_reads 1000 \\\n",
    "    --min_cluster_size 500 \\\n",
    "    --outdir NanoCLUST_NCBI \\\n",
    "    --min_cluster_size 500\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d40b9-6deb-40d3-b1a5-538ff57338ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(1,6):\n",
    "    df = pd.read_csv(f\"Results/NanoCLUST_NCBI/rel_abundance_C{i}S.fastq_S.csv\",)\n",
    "    df['Sample'] = f\"C{i}S\"\n",
    "    dfs.append(df)\n",
    "\n",
    "NC = pd.concat(dfs, ignore_index=True)\n",
    "NC.to_csv(\"Results/NanoCLUST_NCBI/NanoCLUST_taxonomy.tsv\", sep='\\t')\n",
    "display(NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6677db-c724-41d8-acbc-129908347e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"Results/Tools\"\n",
    "\n",
    "NC = pd.read_csv(\"Results/NanoCLUST_NCBI/NanoCLUST_taxonomy.tsv\", sep='\\t', index_col=0)\n",
    "\n",
    "NC = NC.pivot(index=['taxid'], columns='Sample', values='rel_abundance')\n",
    "NC = NC.groupby(['taxid']).sum()\n",
    "NC = NC.reindex(sorted(NC.columns), axis=1)\n",
    "NC.to_csv(\"Results/Tools/NanoCLUST_NCBI.tsv\", sep='\\t')\n",
    "NC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb9576-ab6a-40aa-b558-d66728a56b1c",
   "metadata": {},
   "source": [
    "## Epi2me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe837c1-371c-4a66-aeb5-661ff5861d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in the env. with the nextflow installed\n",
    "\n",
    "BIG = '/home/ty/Big_data/NaMeco_Minion/'\n",
    "inp = f'{BIG}/Standards_sub'\n",
    "\n",
    "clas = ('minimap2', 'kraken2')\n",
    "\n",
    "for cla in clas:\n",
    "    out = f'Results/WF-16S_{cla}'\n",
    "    \n",
    "    !nextflow run epi2me-labs/wf-16s \\\n",
    "    \t--fastq {inp} \\\n",
    "        --classifier {cla} \\\n",
    "        --taxonomic_rank S \\\n",
    "        --threads 10 \\\n",
    "        --min_read_qual 8 \\\n",
    "        --out_dir {out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10ba23-7ba4-4345-b1ac-130bbbf2e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clas = ('minimap2', 'kraken2')\n",
    "dfs = []\n",
    "\n",
    "for cla in clas:\n",
    "    out = f'Results/WF-16S_{cla}'\n",
    "    df = pd.read_csv(f\"{out}/abundance_table_species.tsv\", sep='\\t', index_col=0)\n",
    "    df['Taxon'] = df.Species\n",
    "    df.set_index('Taxon', inplace = True)\n",
    "    df = df[[c for c in df.columns if len(c)==3]]\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df.to_csv(f\"Results/Tools/EPI2ME+{cla.capitalize()}_NCBI.tsv\", sep='\\t')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f45c0-d676-4d92-bc18-4e54f258fb44",
   "metadata": {},
   "source": [
    "## Kraken2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b04dab-a36a-4da0-936c-43b5a0db7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(1,6):\n",
    "    df = pd.read_csv(f'Results/Kraken2/C{i}S.report.txt', sep='\\t', \n",
    "                     names=['Fraction', f'C{i}S', 'Reads', 'Code', 'TaxID', 'Rank', 'NCBI', 'Taxon'])\n",
    "    df = df.loc[df.Rank == 'S']\n",
    "    df.Taxon = df.Taxon.str.strip()\n",
    "    df.set_index('Taxon', inplace=True)\n",
    "    df = df[[c for c in df.columns if len(c)==3]]\n",
    "    dfs.append(df)\n",
    "K2 = pd.concat(dfs, axis=1)\n",
    "K2.to_csv(f\"Results/Tools/Kraken2_standard.tsv\", sep='\\t')\n",
    "display(K2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e48ec4-ec6e-4a6e-bd67-b6dbfddfdb11",
   "metadata": {},
   "source": [
    "## Tools comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7776b42-3764-4afa-ac8c-59b298827022",
   "metadata": {},
   "source": [
    "### Taxonomy barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fbbda-2c64-4b8a-aff4-ce44162ebeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I manually select colors to plot taxonomies with similar colors\n",
    "#for closely classified clusters\n",
    "CDICT = {\n",
    "    'Limosilactobacillus fermentum': 'red',\n",
    "    'Bacillus spizizenii': 'blue',\n",
    "    'Bacillus subtilis': 'navy',\n",
    "    'Bacillus rugosus': 'darkblue',\n",
    "    'Bacillus stercoris': 'royalblue',\n",
    "    'Bacillus halotolerans': 'cornflowerblue',\n",
    "    'Bacillus mojavensis': 'lightsteelblue',\n",
    "    'Bacillus velezensis': 'darkslateblue',\n",
    "    'Bacillus cereus': 'midnightblue',\n",
    "    'Staphylococcus aureus': 'forestgreen',\n",
    "    'Staphylococcus roterodami': 'darkgreen',\n",
    "    'Staphylococcus warneri': 'lime',\n",
    "    'Staphylococcus schleiferi': 'springgreen',\n",
    "    'Staphylococcus piscifermentans': 'palegreen',\n",
    "    'Staphylococcus pasteuri': 'darkseagreen',\n",
    "    'Staphylococcus felis': 'aquamarine',\n",
    "    'Listeria monocytogenes': 'brown',\n",
    "    'Listeria cossartiae': 'maroon',\n",
    "    'Listeria innocua': 'lightcoral',\n",
    "    'Salmonella enterica': 'black',\n",
    "    'Escherichia coli': 'darkgoldenrod',\n",
    "    'Escherichia fergusonii': 'goldenrod',\n",
    "    'Pseudescherichia sp002298805': 'gold',\n",
    "    'Shigella sonnei': 'khaki',\n",
    "    'Shigella flexneri': 'palegoldenrod',\n",
    "    'Enterococcus faecalis': 'fuchsia',\n",
    "    'Enterococcus faecium': 'orchid',\n",
    "    'Pseudomonas aeruginosa': 'hotpink',\n",
    "    'Xanthomonas campestris': 'dimgrey',\n",
    "    'Streptococcus pyogenes': 'slategray',\n",
    "    'Kluyvera ascorbata': 'mistyrose',\n",
    "    'Klebsiella variicola': 'tan',\n",
    "    'Klebsiella pneumoniae': 'burlywood',\n",
    "    'Cronobacter muytjensii': 'peru',\n",
    "    'Citrobacter koseri': 'cyan',\n",
    "    'Unknown': 'dimgray',\n",
    "    'others': 'lightgrey',\n",
    "}\n",
    "\n",
    "TOOLS = [\n",
    "    'Standard_D6306',\n",
    "    'NaMeco_GTDB',\n",
    "    'NanoCLUST_GTDB',\n",
    "    'NaMeco_NCBI',\n",
    "    'NanoCLUST_NCBI',\n",
    "    'EPI2ME+Minimap2_NCBI',\n",
    "    'EPI2ME+Kraken2_NCBI',\n",
    "    'Kraken2_standard',\n",
    "]\n",
    "\n",
    "rows, cols = 1, len(TOOLS)\n",
    "ra, pv = 1, .4 #rel.ab. and prev. thresholds\n",
    "\n",
    "#figure\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(3, 1.8), sharey='row',\n",
    "            gridspec_kw={'wspace': .1, 'width_ratios': [.9] + [4]*(cols-1)})\n",
    "#axs, i = [[r, c] for r in range(rows) for c in range(cols)], 0\n",
    "\n",
    "STD = pd.read_csv(f'Results/Tools/Standard_D6306.tsv', sep='\\t', index_col=0).T\n",
    "STD.columns = [c.replace('Lact','Limosilact').replace('subtilis','spizizenii') for c in STD.columns]\n",
    "legend = STD.columns.tolist()[::-1] + [ c for c in CDICT.keys() if c not in STD.columns.tolist()]\n",
    "labels = STD.columns.tolist()[::-1]\n",
    "\n",
    "#data\n",
    "for i, tool in enumerate(TOOLS):\n",
    "    if tool == TOOLS[0]:\n",
    "        tool = 'Zymo'\n",
    "        df = STD\n",
    "    else:\n",
    "        df = pd.read_csv(f'Results/Tools/{tool}.tsv', sep='\\t', index_col=0).T\n",
    "        df = df.fillna(0)\n",
    "        df = df.div(df.sum(axis=1), axis=0) * 100 #convert to % (rel ab)\n",
    "        others = [c for c in df.columns if df[c].mean() < ra or len(df.loc[df[c]>0])/len(df) < pv]\n",
    "        df['others'] = df[others].sum(axis=1)\n",
    "        df.drop(inplace=True, columns=others)\n",
    "        df = df.reindex([c for c in list(CDICT.keys())[::-1] if c in df.columns.tolist()], axis=1)\n",
    "        labels += [c for c in CDICT.keys() if c not in labels if c in df.columns.tolist()]\n",
    "        tool = tool.replace('+', ' +\\n').replace('_', '\\n(')+')'\n",
    "\n",
    "    #ax, i = axes[axs[i][0]][axs[i][1]], i+1\n",
    "    ax = axes[i]\n",
    "    data = df.copy()\n",
    "    bottom = [0]*len(data)\n",
    "    for col in data.columns: #iterate through all features\n",
    "        c = CDICT[col]\n",
    "        ax.bar(x=data.index, height=data[col], bottom=bottom, color=c, label=col, width=.95, linewidth=0)\n",
    "        bottom = [a + b for a, b in zip(bottom, data[col].tolist())] #update bottom \n",
    "        \n",
    "    #aesthetics\n",
    "    ax.tick_params(axis='both', labelsize=4.5, pad=.5, length=.5, width=0.5) #adjust ticks\n",
    "    ax.tick_params(axis='x', rotation=90) #adjust ticks\n",
    "    #ax.set_xticks([])\n",
    "    ax.set_ylim(0, 100) #set limit for y axis\n",
    "    ax.set_xlim(-.5, len(data.index) - .5) #set limit for x axis\n",
    "    ax.set_ylabel('', fontsize=6.5, labelpad=0)\n",
    "    ax.text(0.5, 1.02, tool, ha='left', va='center', fontsize=5, \n",
    "            transform=ax.transAxes, rotation=90, rotation_mode='anchor')\n",
    "    if tool == \"Zymo\":\n",
    "        ax.set_ylabel(f'Relative abundance (%)', fontsize=6, labelpad=0)\n",
    "\n",
    "#legend\n",
    "labels.append(labels.pop(labels.index('others')))\n",
    "handles = [mpatches.Patch(color=CDICT[l], label=l) for l in labels]\n",
    "\n",
    "leg = ax.legend(handles, labels ,loc=2, bbox_to_anchor=(1, 1.28), fontsize=5, frameon=False,\n",
    "                handletextpad=0.5, handlelength=0.5, bbox_transform=ax.transAxes, ncols=2, \n",
    "                columnspacing=.5)\n",
    "\n",
    "fig.patches.extend([plt.Rectangle((.908, .62), 0.4, 0.455, fill=False, color='grey', alpha=0.4,\n",
    "                                  transform=fig.transFigure, figure=fig)])\n",
    "\n",
    "fig.suptitle('Sample IDs', fontsize=5.5, y=.01, x=.5)\n",
    "plt.savefig(f'Figures/Taxabarplot_tools_species.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310a73c-04a0-4136-b614-02209041306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I manually select colors to plot taxonomies with similar colors\n",
    "#for closely classified clusters\n",
    "CDICT = {\n",
    "    'Limosilactobacillus': 'red',\n",
    "    'Bacillus': 'blue',\n",
    "    'Staphylococcus': 'forestgreen',\n",
    "    'Listeria': 'brown',\n",
    "    'Salmonella': 'black',\n",
    "    'Escherichia': 'darkgoldenrod',\n",
    "    'Pseudescherichia': 'gold',\n",
    "    'Shigella': 'khaki',\n",
    "    'Enterococcus': 'fuchsia',\n",
    "    'Pseudomonas': 'hotpink',\n",
    "    'Xanthomonas': 'dimgrey',\n",
    "    'Streptococcus': 'slategray',\n",
    "    'Kluyvera': 'mistyrose',\n",
    "    'Klebsiella': 'tan',\n",
    "    'Cronobacter': 'peru',\n",
    "    'Citrobacter': 'cyan',\n",
    "    'Unknown': 'dimgray',\n",
    "    'Enterobacter': 'lime',\n",
    "    'Cytobacillus': 'burlywood',\n",
    "    'Erwinia': 'maroon', \n",
    "    'others': 'lightgrey',\n",
    "}\n",
    "\n",
    "TOOLS = [\n",
    "    'Standard_D6306',\n",
    "    'NaMeco_GTDB',\n",
    "    'NanoCLUST_GTDB',\n",
    "    'NaMeco_NCBI',\n",
    "    'NanoCLUST_NCBI',\n",
    "    'EPI2ME+Minimap2_NCBI',\n",
    "    'EPI2ME+Kraken2_NCBI',\n",
    "    'Kraken2_standard',\n",
    "]\n",
    "\n",
    "rows, cols = 1, len(TOOLS)\n",
    "ra, pv = 1, .4 #rel.ab. and prev. thresholds\n",
    "\n",
    "#figure\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(3, 1.9), sharey='row',\n",
    "            gridspec_kw={'wspace': .1, 'width_ratios': [.9] + [4]*(cols-1)})\n",
    "#axs, i = [[r, c] for r in range(rows) for c in range(cols)], 0\n",
    "\n",
    "STD = pd.read_csv(f'Results/Tools/Standard_D6306.tsv', sep='\\t', index_col=0).T\n",
    "STD.columns = [c.replace('Lact','Limosilact').replace('subtilis','spizizenii') for c in STD.columns]\n",
    "STD.columns = [c.split(' ')[0] for c in STD.columns]\n",
    "legend = STD.columns.tolist()[::-1] + [ c for c in CDICT.keys() if c not in STD.columns.tolist()]\n",
    "labels = STD.columns.tolist()[::-1]\n",
    "\n",
    "#data\n",
    "for i, tool in enumerate(TOOLS):\n",
    "    if tool == TOOLS[0]:\n",
    "        df = STD\n",
    "        tool = 'Zymo'\n",
    "    else:\n",
    "        df = pd.read_csv(f'Results/Tools/{tool}.tsv', sep='\\t', index_col=0).T\n",
    "        df = df.fillna(0)\n",
    "        df.columns = [c.split(' ')[0] for c in df.columns]\n",
    "        df = df.groupby(level=0, axis=1).sum() #sum duplicates\n",
    "        df = df.div(df.sum(axis=1), axis=0) * 100 #convert to % (rel ab)\n",
    "        others = [c for c in df.columns if df[c].mean() < ra or len(df.loc[df[c]>0])/len(df) < pv]\n",
    "        df['others'] = df[others].sum(axis=1)\n",
    "        df.drop(inplace=True, columns=others)\n",
    "        df = df.reindex([c for c in list(CDICT.keys())[::-1] if c in df.columns.tolist()], axis=1)\n",
    "        labels += [c for c in CDICT.keys() if c not in labels if c in df.columns.tolist()]\n",
    "        tool = tool.replace('+', ' +\\n').replace('_', '\\n(')+')'\n",
    "    \n",
    "    #ax, i = axes[axs[i][0]][axs[i][1]], i+1\n",
    "    ax = axes[i]\n",
    "    data = df.copy()\n",
    "    bottom = [0]*len(data)\n",
    "    for col in data.columns: #iterate through all features\n",
    "        c = CDICT[col]\n",
    "        ax.bar(x=data.index, height=data[col], bottom=bottom, color=c, label=col, width=.95, linewidth=0)\n",
    "        bottom = [a + b for a, b in zip(bottom, data[col].tolist())] #update bottom \n",
    "        \n",
    "    #aesthetics\n",
    "    ax.tick_params(axis='both', labelsize=4.5, pad=.5, length=.5, width=0.5) #adjust ticks\n",
    "    ax.tick_params(axis='x', labelsize=4.5, rotation=90) #adjust ticks\n",
    "    #ax.set_xticks([])\n",
    "    ax.set_ylim(0, 100) #set limit for y axis\n",
    "    ax.set_xlim(-.5, len(data.index) - .5) #set limit for x axis\n",
    "    ax.set_ylabel('', fontsize=6.5, labelpad=0)\n",
    "    ax.text(0.5, 1.02, tool, ha='left', va='center', fontsize=5, \n",
    "            transform=ax.transAxes, rotation=90, rotation_mode='anchor')\n",
    "    if tool == 'Zymo':\n",
    "        ax.set_ylabel(f'Relative abundance (%)', fontsize=6, labelpad=0)\n",
    "\n",
    "#legend\n",
    "labels.append(labels.pop(labels.index('others')))\n",
    "handles = [mpatches.Patch(color=CDICT[l], label=l) for l in labels]\n",
    "\n",
    "leg = ax.legend(handles, labels ,loc=2, bbox_to_anchor=(1, 1.32), fontsize=5, frameon=False,\n",
    "                handletextpad=0.5, handlelength=0.5, bbox_transform=ax.transAxes)\n",
    "\n",
    "fig.patches.extend([plt.Rectangle((.908, .675), 0.27, 0.43, fill=False, color='grey', alpha=0.4,\n",
    "                                  transform=fig.transFigure, figure=fig)])\n",
    "\n",
    "fig.suptitle('Sample IDs', fontsize=5.5, y=.01, x=.5)\n",
    "plt.savefig(f'Figures/Taxabarplot_tools_genus.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559065c2-05c0-478f-9ab7-d587152ea808",
   "metadata": {},
   "source": [
    "### Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f498623-e91e-4302-8c30-f1a260f77262",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    'Standard_D6306',\n",
    "    'NaMeco_GTDB',\n",
    "    'NanoCLUST_GTDB',\n",
    "    'NaMeco_NCBI',\n",
    "    'NanoCLUST_NCBI',\n",
    "    'EPI2ME+Minimap2_NCBI',\n",
    "    'EPI2ME+Kraken2_NCBI',\n",
    "    'Kraken2_standard',\n",
    "]\n",
    "\n",
    "order = TOOLS[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209ca5e-426a-4643-afcf-55a4878250fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp = pd.read_csv(f'/home/ty/Big_data/NaMeco_Minion/Standards_out/Taxonomy_annotation/GTDB/map.tsv', sep='\\t')\n",
    "ra, pv = .01, .4 #rel.ab. and prev. thresholds\n",
    "\n",
    "for tool in TOOLS:\n",
    "    df = pd.read_csv(f'Results/Tools/{tool}.tsv', sep='\\t', index_col=0)\n",
    "    df = df.fillna(0)\n",
    "    df = df.div(df.sum(axis=0), axis=1) #convert to % (rel ab)\n",
    "    df = df.loc[df.mean(axis=1) >= ra]\n",
    "\n",
    "    fulls = []\n",
    "    for ind in df.index:\n",
    "        pat = ind.split(' ')[0].split('_')[0]\n",
    "        new = ind\n",
    "        for full in mapp.Taxonomy.unique():\n",
    "            if pat in full:\n",
    "                new = full.split(';s__')[0] +';s__' + ind \n",
    "                continue\n",
    "        if new == ind:\n",
    "            new = ind + ' check!'\n",
    "        fulls.append(new.replace(' ', '_'))\n",
    "    df.index = fulls\n",
    "    df.to_csv(f\"Results/Tools/{tool}_full.tsv\", sep='\\t')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ab906-5922-4754-b330-7204317e9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import to qiime2\n",
    "\n",
    "for tool in TOOLS:\n",
    "    \n",
    "    !biom convert \\\n",
    "        -i Results/Tools/{tool}_full.tsv \\\n",
    "        -o Results/Tools/{tool}_full.biom \\\n",
    "        --table-type=\"OTU table\" \\\n",
    "        --to-json\n",
    "    \n",
    "    !qiime tools import \\\n",
    "        --type FeatureTable[RelativeFrequency] \\\n",
    "        --input-path Results/Tools/{tool}_full.biom \\\n",
    "        --input-format BIOMV100Format \\\n",
    "        --output-path Results/Tools/{tool}_full.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e1f53-2047-4bc6-b21f-1766b0c33b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "\n",
    "expected = TOOLS[0]\n",
    "\n",
    "for tool in TOOLS:\n",
    "    if tool == expected:\n",
    "        continue\n",
    "        \n",
    "    !qiime quality-control evaluate-composition \\\n",
    "        --i-expected-features Results/Tools/{expected}_full.qza \\\n",
    "        --i-observed-features Results/Tools/{tool}_full.qza \\\n",
    "        --m-metadata-file Data/mock_map.tsv \\\n",
    "        --m-metadata-column Mock \\\n",
    "        --o-visualization Results/Tools/{tool}_accuracy.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618e571-b805-4f69-a8ff-856089de5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool\n",
    "\n",
    "def get_accuracy(qza):\n",
    "    a = !unzip {qza}\n",
    "    out = a[1].split('/')[0].replace('  inflating: ','')\n",
    "    fneg = pd.read_csv(f\"{out}/data/false_negative_features.tsv\", index_col=0, sep='\\t')\n",
    "    fpos = pd.read_csv(f\"{out}/data/underclassifications.tsv\", index_col=0, sep='\\t')\n",
    "    misc = pd.read_csv(f\"{out}/data/misclassifications.tsv\", index_col=0, sep='\\t')\n",
    "    ress = pd.read_csv(f\"{out}/data/results.tsv\", index_col=0, sep='\\t')\n",
    "    !rm -rf {out}\n",
    "    return fneg, fpos, misc, ress\n",
    "\n",
    "\n",
    "expected = TOOLS[0]\n",
    "dfs = []\n",
    "tabs = ['fneg', 'fpos', 'misc', 'ress']\n",
    "\n",
    "for tool in TOOLS:\n",
    "    if tool == expected:\n",
    "        continue\n",
    "        \n",
    "    qza = f\"Results/Tools/{tool}_accuracy.qzv\"\n",
    "    fneg, fpos, misc, ress = get_accuracy(qza)\n",
    "    for df in (fneg, fpos, misc, ress):\n",
    "        df['Tool'] = tool\n",
    "        df.index = df.index.astype(str).str.split('s__').str[-1]\n",
    "    dfs.append([fneg, fpos, misc, ress])\n",
    "\n",
    "for i, tab in enumerate(tabs):\n",
    "    df = pd.concat([t[i] for t in dfs])\n",
    "    df.to_csv(f\"Results/Tools/{tab}_accuracy.tsv\", sep='\\t')\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617141c0-e6b0-42e9-92b0-a5639c9a18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat analyses (t-test)\n",
    "\n",
    "#parse formula. Borrowed from https://github.com/qiime2/q2-longitudinal\n",
    "def parse_formula(formula): \n",
    "    from patsy import ModelDesc\n",
    "    from statsmodels.formula.api import ols\n",
    "    if '~' not in formula:\n",
    "        raise ValueError('Formula not valid: missing tilde.\\n')\n",
    "    if ';' in formula or formula.strip()[0].isdigit():\n",
    "        metric = formula.split('~')[0].strip()\n",
    "    else: metric = None\n",
    "    # use patsy to parse formula\n",
    "    model_desc = ModelDesc.from_formula(formula)\n",
    "    group_columns = set()\n",
    "    for t in model_desc.rhs_termlist:\n",
    "        for i in t.factors: \n",
    "            group_columns.add(i.name())\n",
    "    if metric is None:\n",
    "        metric = model_desc.lhs_termlist[0].name()\n",
    "    return metric, group_columns\n",
    "\n",
    "\n",
    "#anova\n",
    "def run_anova(formula, data, pairs=False):\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    from patsy import ModelDesc\n",
    "    from statsmodels.formula.api import ols\n",
    "    \n",
    "    metric, group_columns = parse_formula(formula)\n",
    "    columns  = [metric] + list(group_columns)\n",
    "    cats = data.select_dtypes(exclude='number').columns.tolist()\n",
    "    metadata = data[columns].dropna().copy()\n",
    "    lm = ols(formula, metadata).fit()\n",
    "    results = pd.DataFrame(sm.stats.anova_lm(lm, typ='II')).fillna('')\n",
    "    # Run pairwise t-tests with multiple test correction\n",
    "    pairwise_tests = pd.DataFrame()\n",
    "    for group in group_columns:\n",
    "        # only run on categorical columns — numeric columns raise error\n",
    "        if group in cats:\n",
    "            ttests = lm.t_test_pairwise(group, method='fdr_bh').result_frame\n",
    "            pairwise_tests = pd.concat([pairwise_tests, pd.DataFrame(ttests)])\n",
    "    if pairwise_tests.empty:\n",
    "        pairwise_tests = False  \n",
    "    # Plot fit vs. residuals\n",
    "    metadata['residual'] = lm.resid\n",
    "    metadata['fitted_values'] = lm.fittedvalues\n",
    "    return results, pairwise_tests, metadata\n",
    "\n",
    "\n",
    "levs = {\n",
    "    'Genus': 6,\n",
    "    'Species': 7,\n",
    "}\n",
    "\n",
    "renames = {\n",
    "    'Observed / Expected Taxa': 'OET',\n",
    "    'P value': 'P_value',\n",
    "    'Std Err': 'StdErr',\n",
    "    'Bray-Curtis': 'Bray_Curtis',\n",
    "    'r-squared': 'r_squared',\n",
    "    \n",
    "}\n",
    "\n",
    "ress = pd.read_csv(f\"Results/Tools/ress_accuracy.tsv\", sep='\\t', index_col='sample')\n",
    "ress = ress.rename(columns=renames)\n",
    "anova, pairwise, residuals = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "facts = ['OET', 'TAR', 'TDR', 'Slope', 'P_value', 'StdErr', 'Bray_Curtis', 'Jaccard', 'r_squared']\n",
    "\n",
    "for lev, l in levs.items():\n",
    "    df = ress.loc[ress.level == l]\n",
    "    for fact in facts:\n",
    "        data = df[(df[fact].notna())].copy()\n",
    "        formula= f'{fact} ~ Tool'\n",
    "        results, pairwise_tests, data = run_anova(formula, data)\n",
    "        results['Metric'] = pairwise_tests['Metric'] = data['Metric'] = fact\n",
    "        results['Factor'] = pairwise_tests['Factor'] = data['Factor'] = 'Tool'\n",
    "        results['Level'] = pairwise_tests['Level'] = data['Level'] = lev\n",
    "        anova = pd.concat([anova, results])\n",
    "        pairwise = pd.concat([pairwise, pairwise_tests])\n",
    "        residuals = pd.concat([residuals, data])\n",
    "anova.to_csv(f'Results/Tools/anova.tsv', sep='\\t')\n",
    "pairwise.to_csv(f'Results/Tools/anova_pairs.tsv', sep='\\t')\n",
    "residuals.to_csv(f'Results/Tools/anova_residuals.tsv', sep='\\t')\n",
    "display(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b9047-3772-472b-a4f0-ddecad4c4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod -R 755 ~/Nextcloud*/Tools/*\n",
    "!../../Tools/cld.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79b522-3c34-4198-ac4a-520356966d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cld and plots\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append(glob.glob('/home/*/Dropbox/TY_scripts/')[0])\n",
    "from TY_stats import *\n",
    "    \n",
    "levs = {\n",
    "    'Genus': 6,\n",
    "    'Species': 7,\n",
    "}\n",
    "\n",
    "renames = {\n",
    "    'Observed / Expected Taxa': 'OET',\n",
    "    'P value': 'P_value',\n",
    "    'Std Err': 'StdErr',\n",
    "    'Bray-Curtis': 'Bray_Curtis',\n",
    "    'r-squared': 'r_squared',\n",
    "    \n",
    "}\n",
    "\n",
    "SUBS = {\n",
    "    'Observed / Expected Taxa': \"Observed /\\nexpected taxa\", \n",
    "    'TAR': 'Taxon\\naccuracy rate', \n",
    "    'TDR': 'Taxon\\ndetection rate', \n",
    "    'Bray-Curtis': 'Bray-Curtis\\ndistances',\n",
    "    'P value': 'Regression\\np-value', \n",
    "    'r-squared': 'Regression\\nr$^2$-value'}\n",
    "\n",
    "pairs = pd.read_csv(f'Results/Tools/anova_pairs.tsv', sep='\\t')\n",
    "pairs[['Group1', 'Group2']] = pairs['Unnamed: 0'].str.split('-', expand=True)\n",
    "ress = pd.read_csv(f\"Results/Tools/ress_accuracy.tsv\", sep='\\t', index_col='sample')\n",
    "\n",
    "\n",
    "#set figure\n",
    "rows, cols = 1, len(SUBS)\n",
    "\n",
    "for lev, l in levs.items():\n",
    "    #figure\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4.4, 1.9), sharey='row',\n",
    "                gridspec_kw={'wspace': .08})\n",
    "    #axs, i = [[r, c] for r in range(rows) for c in range(cols)], 0\n",
    "    \n",
    "    for i, fact in enumerate(SUBS):\n",
    "        data = ress.loc[(ress.level == l)].copy()\n",
    "        data = data[(data[fact].notna())]\n",
    "        means = pd.DataFrame(data.groupby('Tool')[fact].mean()).sort_values(fact, ascending=False).index.tolist()\n",
    "\n",
    "        ### Boxplots ###\n",
    "        #ax, i = axes[axs[i][0]][axs[i][1]], i+1\n",
    "        ax = axes[i]\n",
    "        sns.boxplot(x=fact, y='Tool', data=data, ax=ax, linewidth=0.4, fliersize=0.3, \n",
    "                    order=order, color='white', showfliers=True)\n",
    "        #sns.violinplot(x=fact, y='Tool', data=data, ax=ax, order=order, )\n",
    "        sns.swarmplot(x=fact, y='Tool', data=data, order=order, ax=ax, size=2, \n",
    "                      alpha=0.9, legend=False, c='black')\n",
    "        ax.tick_params(axis='both', labelsize=5, length=1.5, pad=1, width=0.5, direction='inout', rotation=45)\n",
    "        ax.tick_params(axis='y', labelsize=5, rotation=0)\n",
    "        ax.set_yticklabels([l.replace('_', '\\n(')+')' for l in order])\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('')\n",
    "        ax.grid(lw=.5, ls='--')\n",
    "        if fact == list(SUBS.keys())[0]: \n",
    "            ax.set_ylabel(f'Tool and database accuracy at {lev} level', fontsize=6, labelpad=1)\n",
    "        ax.text(.5, 1.04, SUBS[fact], ha='center', fontsize=5.5, transform=ax.transAxes)\n",
    "        #[axc.set_linewidth(0.5) for axc in ax.collections]\n",
    "\n",
    "        #add stat letter\n",
    "        if fact not in ['P value', 'r-squared']:\n",
    "            xmin, xmax = data[fact].min(), data[fact].max()\n",
    "            xm = xmin - (xmax-xmin)/2\n",
    "            ax.set_xlim(xm, xmax*1.1)\n",
    "            if fact in renames:\n",
    "                fact = renames[fact]\n",
    "            statsdf = pairs.loc[(pairs.Level == lev) & (pairs.Metric == fact)].copy()\n",
    "            cld = ABCstat(statsdf,'Group1', 'Group2', 'pvalue-fdr_bh', order=means)\n",
    "            #print(fact, lev)\n",
    "            #display(statsdf[['Group1', 'Group2', 'pvalue-fdr_bh', 'reject-fdr_bh']])\n",
    "            for iy, y in enumerate(order):\n",
    "                letter = cld.loc[y, 'letters']\n",
    "                ax.text(xm, iy, f\" {letter}\", size=6, ha='left', va='center', color='black', )\n",
    "    plt.savefig(f'Figures/Accuracy_{lev}.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790ad86-3a00-464b-874a-0fde30c221b1",
   "metadata": {},
   "source": [
    "### Percent Identities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d85878-9abc-4f67-a1ff-64aa34f5b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wicoxon or ttest for 2 groups of dependent samples\n",
    "def dependent_test(df, col, metric, index, method='wilcoxon'):\n",
    "    data = df.pivot_table(index=[index], columns=col, values=metric)\n",
    "    if method not in ['wilcoxon', 'ttest']:\n",
    "        raise ValueError('Method should be either \"wilcoxon\" or \"ttest\"')\n",
    "    if method == 'wilcoxon':\n",
    "        out = stats.wilcoxon(data[data.columns[0]], data[data.columns[1]], nan_policy='omit')\n",
    "    if method == 'ttest':\n",
    "        out = stats.ttest_rel(data[data.columns[0]], data[data.columns[1]], nan_policy='omit')\n",
    "    return out\n",
    "\n",
    "\n",
    "out = 'Results/Tools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3adb75-efcf-415d-9dd5-9d97dac275ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBs = ['GTDB', 'NCBI']\n",
    "\n",
    "dfs = []\n",
    "for db in DBs:\n",
    "    df = pd.read_csv(f'Results/Standards/{db}-taxonomy.tsv', sep='\\t', usecols=['Cluster', 'Perc. id.'])\n",
    "    df['DB'] = db\n",
    "    dfs.append(df)\n",
    "data = pd.concat(dfs, ignore_index=True)    \n",
    "data.to_csv(f'{out}/PercId_GTDBvsNCBI.tsv', sep='\\t',)\n",
    "\n",
    "summ = pd.DataFrame()\n",
    "test = dependent_test(df=data, col='DB', metric='Perc. id.', index='Cluster', method='wilcoxon')\n",
    "summ.loc[0, ['Metric', 'Factor']] = ['Perc. id.', 'DB']\n",
    "summ.loc[0, ['P', 'Stats', 'Method']] = [test[1], test[0], 'wilcoxon']\n",
    "summ.to_csv(f'{out}/Dependent_test_GTDBvsNCBI.tsv', sep='\\t', index=False)\n",
    "\n",
    "display(summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f475fdd-5fb9-47e6-b519-76ba283ca3a9",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92818c75-635a-475d-aa4e-54813a96f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBs = ['GTDB', 'NCBI']\n",
    "rows = 1\n",
    "cols = 1\n",
    "\n",
    "data = pd.read_csv(f'{out}/PercId_GTDBvsNCBI.tsv', sep='\\t', index_col=0)\n",
    "summ = pd.read_csv(f'{out}/Dependent_test_GTDBvsNCBI.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "#set figure\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(.8, 1.8))\n",
    "\n",
    "### Boxplots ###\n",
    "sns.boxplot(x='DB', y='Perc. id.', data=data, ax=ax, linewidth=0.4, fliersize=0.3, \n",
    "            order=DBs, color='white', showfliers=False, )\n",
    "sns.swarmplot(x='DB', y='Perc. id.', data=data, order=DBs, ax=ax, size=2, \n",
    "              alpha=0.6, legend=False, c='black', )\n",
    "ax.tick_params(axis='both', labelsize=5, length=1.5, pad=1, width=0.5, direction='inout')\n",
    "ax.tick_params(axis='x', labelsize=6, )\n",
    "ax.set_xlabel('') \n",
    "ax.set_ylabel('Percent identity', fontsize=6, labelpad=0)\n",
    "#ax.text(.5, 1.14, \"GTDB vs NCBI\", ha='center', fontsize=7, transform=ax.transAxes)\n",
    "\n",
    "#line color/width\n",
    "for patch in ax.patches:\n",
    "    patch.set_edgecolor('black')\n",
    "    patch.set_linewidth(.5)\n",
    "plt.setp(ax.lines, color='k', lw=.5)\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "#Statistics\n",
    "#p-general\n",
    "color = 'grey'\n",
    "p_gen = round(summ.P[0], 4)\n",
    "p = f'P = {p_gen}'\n",
    "if p_gen == 0.0:\n",
    "    p = f'P < 0.0001'\n",
    "if p_gen <= 0.05:\n",
    "    color = 'black'\n",
    "ax.text(.5, 1.02, p, size=5.5, transform=ax.transAxes, ha='center', color=color)\n",
    "\n",
    "plt.savefig(f'Figures/GTDBvsNCBI.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qiime2-amplicon-2023.9]",
   "language": "python",
   "name": "conda-env-qiime2-amplicon-2023.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
